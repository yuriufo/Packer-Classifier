{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 系统演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 驱动器 F 中的卷是 新加卷\n",
      " 卷的序列号是 A8C1-0BCD\n",
      "\n",
      " F:\\course\\gp\\Packer-Classifier 的目录\n",
      "\n",
      "2019/05/27  17:49    <DIR>          .\n",
      "2019/05/27  17:49    <DIR>          ..\n",
      "2019/05/27  13:11    <DIR>          .ipynb_checkpoints\n",
      "2019/05/10  22:07    <DIR>          .vscode\n",
      "2019/05/27  17:03    <DIR>          Datasets\n",
      "2019/05/27  16:56    <DIR>          experiments\n",
      "2019/05/27  17:12    <DIR>          gadgets\n",
      "2019/05/27  17:18            12,509 img_train.py\n",
      "2019/05/18  00:28            15,774 ins_train.py\n",
      "2019/05/27  17:19            17,872 main_train.py\n",
      "2019/05/27  17:12    <DIR>          my_models\n",
      "2019/05/27  13:42    <DIR>          my_sandbox\n",
      "2019/05/12  22:07    <DIR>          pin\n",
      "2019/05/27  17:49            18,847 presentation.ipynb\n",
      "2019/05/27  13:46    <DIR>          pre_data\n",
      "2019/04/20  09:13               407 README.md\n",
      "2019/05/27  17:20    <DIR>          __pycache__\n",
      "               5 个文件         65,409 字节\n",
      "              12 个目录 64,239,796,224 可用字节\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相关参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    \"seed\": 519,\n",
    "    \"vectorizer_file\": \"vectorizer.json\",\n",
    "    \"model_state_file\": \"model.pth\",\n",
    "    \"save_dir\": Path.cwd() / \"experiments\" / \"main\" / \"1558276575_74f6ab40-7a43-11e9-8b2b-0242ac1c0002\",\n",
    "    # ODEnet\n",
    "    \"input_dim\": 3,\n",
    "    \"state_dim\": 64,\n",
    "    \"tol\": 5e-5,\n",
    "    # GRU\n",
    "    \"cutoff\": 25,\n",
    "    \"num_layers\": 1,\n",
    "    \"embedding_dim\": 100,\n",
    "    \"kernels\": [1, 3],\n",
    "    \"num_filters\": 100,\n",
    "    \"rnn_hidden_dim\": 64,\n",
    "    \"hidden_dim\": 36,\n",
    "    \"dropout_p\": 0.5,\n",
    "    \"bidirectional\": False,\n",
    "    # 超参数, [训练, 验证, 测试]\n",
    "    \"state_size\": [0.7, 0.15, 0.15],\n",
    "    \"batch_size\": 26,\n",
    "    \"num_epochs\": 50,\n",
    "    \"early_stopping_criteria\": 5,\n",
    "    \"learning_rate\": 1e-5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征提取准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sandbox类\n",
    "\n",
    "* vmrun_path：vmrun.exe路径\n",
    "* vmx_path：虚拟机.vmx路径\n",
    "* vm_snapshot：虚拟机快照名real\n",
    "* vm_user：虚拟机用户名\n",
    "* vm_pass：虚拟机密码\n",
    "* script_path：虚拟机内Python脚本路径\n",
    "* python_path：虚拟机内Python路径\n",
    "* malware_path：虚拟机内暂存样本路径\n",
    "* timeout：运行脚本超时时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_sandbox.get_features import Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb = Sandbox(\n",
    "        vmrun_path=r\"E:\\VMware\\vmrun.exe\",\n",
    "        vmx_path=r\"D:\\虚拟机\\Win10\\Windows 10 x64.vmx\",\n",
    "        vm_snapshot=\"real\",\n",
    "        vm_user=\"msi\",\n",
    "        vm_pass=\"123456\",\n",
    "        script_path=r\"C:\\Users\\msi\\Desktop\\my_sandbox_script.py\",\n",
    "        python_path=r\"C:\\Users\\msi\\AppData\\Local\\Programs\\Python\\Python35\\python.exe\",\n",
    "        malware_path=r\"C:\\Malware\",\n",
    "        timeout=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre_data.preprocess import Preproce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = Preproce()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载向量器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from Datasets.datasets import Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_filepath = config['save_dir'] / config['vectorizer_file']\n",
    "with vectorizer_filepath.open() as fp:\n",
    "    vectorizer = Vectorizer.from_serializable(json.load(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IMG_SequenceVocabulary(train_means: [128.47567749023438, 93.32111358642578, 38.726646423339844], train_stds: [59.69920349121094, 89.16869354248047, 61.76454162597656]>\n",
      "<INS_SequenceVocabulary(size=106)>\n",
      "<INS_SequenceVocabulary(size=34)>\n",
      "<Vocabulary(size=7)>\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.image_vocab)\n",
    "print(vectorizer.ins_word_vocab)\n",
    "print(vectorizer.ins_char_vocab)\n",
    "print(vectorizer.packer_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_train import MainModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MainModel(\n",
    "    input_dim=config[\"input_dim\"],\n",
    "    state_dim=config[\"state_dim\"],\n",
    "    tol=config[\"tol\"],\n",
    "    embedding_dim=config[\"embedding_dim\"],\n",
    "    num_word_embeddings=len(vectorizer.ins_word_vocab),\n",
    "    num_char_embeddings=len(vectorizer.ins_char_vocab),\n",
    "    kernels=config[\"kernels\"],\n",
    "    num_input_channels=config[\"embedding_dim\"],\n",
    "    num_output_channels=config[\"num_filters\"],\n",
    "    rnn_hidden_dim=config[\"rnn_hidden_dim\"],\n",
    "    hidden_dim=config[\"hidden_dim\"],\n",
    "    output_dim=len(vectorizer.packer_vocab),\n",
    "    num_layers=config[\"num_layers\"],\n",
    "    bidirectional=config[\"bidirectional\"],\n",
    "    dropout_p=config[\"dropout_p\"],\n",
    "    word_padding_idx=vectorizer.ins_word_vocab.mask_index,\n",
    "    char_padding_idx=vectorizer.ins_char_vocab.mask_index)\n",
    "\n",
    "model.load_state_dict(torch.load(config['save_dir'] / config['model_state_file']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_modules of MainModel(\n",
      "  (img_layer): IngModel(\n",
      "    (downsampling_layers): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace)\n",
      "      (3): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (4): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "      (5): ReLU(inplace)\n",
      "      (6): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (feature_layers): ODEBlock(\n",
      "      (odefunc): ODEfunc(\n",
      "        (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv1): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "        (conv2): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (fc_layers): Sequential(\n",
      "      (0): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "      (1): ReLU(inplace)\n",
      "      (2): AdaptiveAvgPool2d(output_size=1)\n",
      "      (3): Flatten()\n",
      "    )\n",
      "  )\n",
      "  (ins_layer): InsModel(\n",
      "    (encoder): InsEncoder(\n",
      "      (word_embeddings): Embedding(106, 100, padding_idx=0)\n",
      "      (char_embeddings): Embedding(34, 100, padding_idx=0)\n",
      "      (conv): ModuleList(\n",
      "        (0): Conv1d(100, 100, kernel_size=(1,), stride=(1,))\n",
      "        (1): Conv1d(100, 100, kernel_size=(3,), stride=(1,))\n",
      "      )\n",
      "      (gru): GRU(300, 64, batch_first=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (decoder): InsDecoder(\n",
      "      (fc_attn): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (fc_layers): Sequential(\n",
      "        (0): Dropout(p=0.5)\n",
      "        (1): Linear(in_features=64, out_features=36, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): ReLU(inplace)\n",
      "    (1): Dropout(p=0.5)\n",
      "    (2): Linear(in_features=100, out_features=7, bias=True)\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "model = model.to(\"cpu\")\n",
    "print (model.named_modules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inference(object):\n",
    "    def __init__(self, model, vectorizer):\n",
    "        self.model = model\n",
    "        self.vectorizer = vectorizer\n",
    "\n",
    "    def predict_packer(self, image, ins):\n",
    "        # 向量化\n",
    "        image_vector, ins_word_vector, ins_char_vector, ins_length = self.vectorizer.vectorize(image, ins)\n",
    "        \n",
    "        image_vector = torch.FloatTensor(image_vector).unsqueeze(0)\n",
    "        ins_word_vector = torch.tensor(ins_word_vector).unsqueeze(0)\n",
    "        ins_char_vector = torch.tensor(ins_char_vector).unsqueeze(0)\n",
    "        ins_length = torch.tensor([ins_length]).long()\n",
    "\n",
    "        # 预测\n",
    "        self.model.eval()\n",
    "        attn_scores, y_pred = self.model(x_img=image_vector,\n",
    "                                         x_word=ins_word_vector,\n",
    "                                         x_char=ins_char_vector,\n",
    "                                         x_lengths=ins_length,\n",
    "                                         device=\"cpu\",\n",
    "                                         apply_softmax=True)\n",
    "\n",
    "        # 取概率最大\n",
    "        y_prob, indices = y_pred.max(dim=1)\n",
    "        index = indices.item()\n",
    "\n",
    "        # 预测壳类型\n",
    "        packer = vectorizer.packer_vocab.lookup_index(index)\n",
    "        probability = y_prob.item()\n",
    "        return {'packer': packer, 'probability': probability, \n",
    "                'attn_scores': attn_scores}\n",
    "\n",
    "    def predict_top_k(self, image, ins, k):\n",
    "        # 向量化\n",
    "        image_vector, ins_word_vector, ins_char_vector, ins_length = self.vectorizer.vectorize(image, ins)\n",
    "        \n",
    "        image_vector = torch.FloatTensor(image_vector).unsqueeze(0)\n",
    "        ins_word_vector = torch.tensor(ins_word_vector).unsqueeze(0)\n",
    "        ins_char_vector = torch.tensor(ins_char_vector).unsqueeze(0)\n",
    "        ins_length = torch.tensor([ins_length]).long()\n",
    "\n",
    "         # 预测\n",
    "        self.model.eval()\n",
    "        _, y_pred = self.model(x_img=image_vector,\n",
    "                               x_word=ins_word_vector,\n",
    "                               x_char=ins_char_vector,\n",
    "                               x_lengths=ins_length,\n",
    "                               device=\"cpu\",\n",
    "                               apply_softmax=True)\n",
    "        \n",
    "        # Top k\n",
    "        y_prob, indices = torch.topk(y_pred, k=k)\n",
    "        probabilities = y_prob.detach().numpy()[0]\n",
    "        indices = indices.detach().numpy()[0]\n",
    "\n",
    "        # 结果\n",
    "        results = []\n",
    "        for probability, index in zip(probabilities, indices):\n",
    "            packer = self.vectorizer.packer_vocab.lookup_index(index)\n",
    "            results.append({'packer': packer, 'probability': probability})\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = r\"C:\\Users\\msi\\Desktop\\aspack变形.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> revertToSnapshot\n",
      "--> start\n",
      "--> copyFileFromHostToGuest\n",
      "--> runProgramInGuest\n",
      "--> copyFileFromGuestToHost\n",
      "--> stop\n",
      "--> get features\n",
      "--> completed!\n"
     ]
    }
   ],
   "source": [
    "# 输入要检测的文件路径，得到特征\n",
    "features = sb.get_features(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0x0044d001 9c --> pushfd '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.split(\"\\n\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = pp.preprocess(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data_dict['image'][0]\n",
    "ins = data_dict['ins'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msi\\Desktop\\aspack变形.exe → ASPack (p=1.00)\n"
     ]
    }
   ],
   "source": [
    "inference = Inference(model=model, vectorizer=vectorizer)\n",
    "prediction = inference.predict_packer(data_dict['image'][0], data_dict['ins'][0])\n",
    "print(\"{} → {} (p={:0.2f})\".format(input_path, prediction['packer'], \n",
    "                                    prediction['probability']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msi\\Desktop\\aspack变形.exe: \n",
      "ASPack (p=1.00)\n",
      "PeSpin (p=0.00)\n",
      "Molebox (p=0.00)\n",
      "Normal (p=0.00)\n",
      "NsPack (p=0.00)\n",
      "PECompact (p=0.00)\n",
      "UPX (p=0.00)\n"
     ]
    }
   ],
   "source": [
    "# Top-k\n",
    "top_k = inference.predict_top_k(img, ins, k=len(vectorizer.packer_vocab))\n",
    "print (\"{}: \".format(input_path))\n",
    "for result in top_k:\n",
    "    print (\"{} (p={:0.2f})\".format(result['packer'], \n",
    "                                   result['probability']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
